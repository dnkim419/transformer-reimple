{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " # This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = 'backup'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# Change dariectory to current folder\n",
        "%cd /content/drive/MyDrive/$FOLDERNAME"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfEd6RWKTNLx",
        "outputId": "35fe28cf-0b9f-4a96-ad04-4af4b9b9f9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/backup\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_7jFfZ7S-UF",
        "outputId": "a973131a-41e5-423a-fd37-c67b8e22e93e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "de_vocab_file = 'de.model'\n",
        "en_vocab_file = 'en.model'\n",
        "\n",
        "de_vocab = spm.SentencePieceProcessor()\n",
        "en_vocab = spm.SentencePieceProcessor()\n",
        "\n",
        "# de, en vocab 로드\n",
        "de_vocab.load(de_vocab_file)\n",
        "en_vocab.load(en_vocab_file)"
      ],
      "metadata": {
        "id": "6cwPkGfOKCgn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e6e1d38-006e-4159-c78b-2d5abe03d071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "JaF-WD5XS7_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTokkPPlwef_"
      },
      "outputs": [],
      "source": [
        "# data.py\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "# mt Dataset\n",
        "class MtDataset(Dataset):\n",
        "  def __init__(self, src_vocab, trg_vocab, df, src_name, trg_name):\n",
        "    self.src_vocab  = src_vocab\n",
        "    self.trg_vocab = trg_vocab\n",
        "    self.src_train = []\n",
        "    self.trg_train = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "      src_line = row[src_name]\n",
        "      trg_line = row[trg_name]\n",
        "      if type(src_line) != str or type(trg_line) != str:\n",
        "        continue\n",
        "      # src 문장, trg 문장 각각 tokenize\n",
        "      self.src_train.append(src_vocab.encode_as_ids(src_line))\n",
        "      self.trg_train.append(trg_vocab.encode_as_ids(trg_line))\n",
        "\n",
        "  def __len__(self):\n",
        "    assert len(self.src_train) == len(self.trg_train)\n",
        "    return len(self.src_train)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return (torch.tensor(self.src_train[idx]), torch.tensor(self.trg_train[idx]))\n",
        "\n",
        "'''\n",
        "read the csv in __init__ but leave the reading of images to __getitem__\n",
        "'''\n",
        "\n",
        "\n",
        "# mt data collate_fn\n",
        "# 배치 단위로 데이터 처리\n",
        "def mt_collate_fn(inputs):\n",
        "  enc_inputs, dec_inputs = list(zip(*inputs)) # to do\n",
        "\n",
        "  # 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0) 추가\n",
        "  enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True)\n",
        "  dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True)\n",
        "\n",
        "  batch = [\n",
        "      enc_inputs,\n",
        "      dec_inputs\n",
        "  ]\n",
        "\n",
        "  return batch # DataLoader iterate 할 때 return됨\n",
        "\n",
        "\n",
        "# DataLoader\n",
        "def build_mt_data_loader(src_vocab, trg_vocab, df, src_name, trg_name, args, shuffle=True):\n",
        "  # Dataset 생성\n",
        "  dataset = MtDataset(src_vocab, trg_vocab, df, src_name, trg_name)\n",
        "  if 1 < args['n_gpu'] and shuffle:\n",
        "    sampler = DistributedSampler(dataset)\n",
        "    loader = DataLoader(dataset, batch_size=args['batch'], sampler=sampler, collate_fn=mt_collate_fn)\n",
        "  else:\n",
        "    sampler = None\n",
        "    loader = DataLoader(dataset, batch_size=args['batch'], sampler=sampler, shuffle=shuffle, collate_fn=mt_collate_fn)\n",
        "\n",
        "  return loader, sampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = MtDataset(en_vocab, de_vocab, train_df, 'en', 'de')"
      ],
      "metadata": {
        "id": "vTu0USVCSVKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXsc8tdBezz7",
        "outputId": "1e62c62b-1028-46db-f70a-3c175a4fb78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "206112"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.__getitem__(123456)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elPbpS0KfK4j",
        "outputId": "e3f70a10-005d-4315-c9ac-dd45a3047268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  35,  891,   41,    8,  436,  653,  210,   54,   25,  690,   41,  225,\n",
              "           50,  311, 7956, 7933, 1375, 1977,   25,  221, 6576, 7951,  109,   99,\n",
              "         4232, 7951,   36,   60, 7956, 7938,  117,  225,  109,  711, 1023, 7953]),\n",
              " tensor([ 145,  850, 7937,   18, 4993, 1133,   61, 7937,   46,  922, 7937,  107,\n",
              "          207,   59,  491, 6109, 4482,  232,  452,  258, 4958,  137, 3889, 7937,\n",
              "           91, 7541, 2196,   35,   83,   61, 7937,  303,  574,   91,  550, 3398,\n",
              "         2141, 7940]))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[123456]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yaXPBDsU360",
        "outputId": "fd0cdd39-caaa-498c-cc00-b6b336f9514f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([  35,  891,   41,    8,  436,  653,  210,   54,   25,  690,   41,  225,\n",
              "           50,  311, 7956, 7933, 1375, 1977,   25,  221, 6576, 7951,  109,   99,\n",
              "         4232, 7951,   36,   60, 7956, 7938,  117,  225,  109,  711, 1023, 7953]),\n",
              " tensor([ 145,  850, 7937,   18, 4993, 1133,   61, 7937,   46,  922, 7937,  107,\n",
              "          207,   59,  491, 6109, 4482,  232,  452,  258, 4958,  137, 3889, 7937,\n",
              "           91, 7541, 2196,   35,   83,   61, 7937,  303,  574,   91,  550, 3398,\n",
              "         2141, 7940]))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "args = {\n",
        "    'n_gpu': 1,\n",
        "    'batch': 2 #256\n",
        "}\n",
        "\n",
        "loader, sampler = build_mt_data_loader(en_vocab, de_vocab, train_df, 'en', 'de', args)\n",
        "\n",
        "cnt = 0\n",
        "\n",
        "for d in loader:\n",
        "  if (cnt < 1):\n",
        "    print(d)\n",
        "    cnt+= 1\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "id": "L8-MfsTjgEJr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09640272-14c5-4b07-b7e6-a53aeb865bae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[1777,  566, 4475, 4676, 6065, 7953,    0,    0,    0,    0,    0,    0,\n",
            "            0,    0,    0,    0,    0],\n",
            "        [ 353,  787, 7982, 3101,    8,  955,  318,  124,  480,   25, 1337,  681,\n",
            "         4283,   25, 2594,  903, 7953]]), tensor([[ 116,   18,  480,   35, 1181,   49,  982,   66, 4722, 7940,    0,    0,\n",
            "            0,    0,    0,    0,    0,    0,    0],\n",
            "        [3718,  377,  227,  833, 5867,  269,  138,   18, 2383,  116, 1445, 2888,\n",
            "         5004, 6342, 7940,  342, 5929,  232, 7940]])]\n"
          ]
        }
      ]
    }
  ]
}
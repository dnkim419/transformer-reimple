{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4190,
     "status": "ok",
     "timestamp": 1701147007977,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "gLoHbtevs1rg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7687,
     "status": "ok",
     "timestamp": 1701147015651,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "xQXCZHKks4Ao",
    "outputId": "7d9bedd2-dcf6-4bcc-f052-ed60b355145a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\dmis\\anaconda3\\envs\\dnkim419\\lib\\site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1701147016529,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "KCYRI2rms596",
    "outputId": "517c382b-6384-43bd-b439-e36920360669",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "de_vocab_file = '../vocab/de.model'\n",
    "en_vocab_file = '../vocab/en.model'\n",
    "\n",
    "de_vocab = spm.SentencePieceProcessor()\n",
    "en_vocab = spm.SentencePieceProcessor()\n",
    "\n",
    "# de, en vocab 로드\n",
    "de_vocab.load(de_vocab_file)\n",
    "en_vocab.load(en_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3180,
     "status": "ok",
     "timestamp": 1701147019705,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "ZiDEcYc1s6aQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701147019705,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Ph47lkGws71E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data.py\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "# mt Dataset\n",
    "class MtDataset(Dataset):\n",
    "  def __init__(self, src_vocab, trg_vocab, df, src_name, trg_name):\n",
    "    self.src_vocab  = src_vocab\n",
    "    self.trg_vocab = trg_vocab\n",
    "    self.src_train = []\n",
    "    self.trg_train = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "      src_line = row[src_name]\n",
    "      trg_line = row[trg_name]\n",
    "      if type(src_line) != str or type(trg_line) != str:\n",
    "        continue\n",
    "      # src 문장, trg 문장 각각 tokenize\n",
    "      self.src_train.append(src_vocab.encode_as_ids(src_line))\n",
    "      self.trg_train.append(trg_vocab.encode_as_ids(trg_line))\n",
    "\n",
    "  def __len__(self):\n",
    "    assert len(self.src_train) == len(self.trg_train)\n",
    "    return len(self.src_train)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return (torch.tensor(self.src_train[idx]), torch.tensor(self.trg_train[idx]))\n",
    "\n",
    "\n",
    "# mt data collate_fn\n",
    "# 배치 단위로 데이터 처리\n",
    "def mt_collate_fn(inputs):\n",
    "  enc_inputs, dec_inputs = list(zip(*inputs)) # to do\n",
    "\n",
    "  # 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0) 추가\n",
    "  enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True)\n",
    "  dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True)\n",
    "\n",
    "  batch = [\n",
    "      enc_inputs,\n",
    "      dec_inputs\n",
    "  ]\n",
    "\n",
    "  return batch # DataLoader iterate 할 때 return됨\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "def build_mt_data_loader(src_vocab, trg_vocab, df, src_name, trg_name, args, shuffle=True):\n",
    "  # Dataset 생성\n",
    "  dataset = MtDataset(src_vocab, trg_vocab, df, src_name, trg_name)\n",
    "  if 1 < args['n_gpu'] and shuffle:\n",
    "    sampler = DistributedSampler(dataset)\n",
    "    loader = DataLoader(dataset, batch_size=args['batch_size'], sampler=sampler, collate_fn=mt_collate_fn)\n",
    "  else:\n",
    "    sampler = None\n",
    "    loader = DataLoader(dataset, batch_size=args['batch_size'], sampler=sampler, shuffle=shuffle, collate_fn=mt_collate_fn)\n",
    "\n",
    "  return loader, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701147019705,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "OstDP6dgs9oS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_config = {\n",
    "    \"n_gpu\": 1, #tmp\n",
    "    \"n_layer\": 6,\n",
    "    \"batch_size\": 256,\n",
    "    \"n_enc_vocab\": 8000, # tmp\n",
    "    \"n_dec_vocab\": 8000, # tmp\n",
    "    \"n_enc_seq\": 80, # tmp\n",
    "    \"n_dec_seq\": 80, # tmp\n",
    "    \"d_model\": 512,\n",
    "    \"d_ff\": 2048,\n",
    "    \"h\": 8,\n",
    "    \"d_h\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"layer_norm_epsilon\": 1e-12,\n",
    "    \"i_pad\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 65175,
     "status": "ok",
     "timestamp": 1701147084878,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "MXapKd_Ms_EI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'n_gpu': tmp_config['n_gpu'],\n",
    "    'batch_size': tmp_config['batch_size'],\n",
    "}\n",
    "\n",
    "loader, sampler = build_mt_data_loader(en_vocab, de_vocab, train_df, 'en', 'de', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Duu2oIKEtM-G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sinusoidal position representations\n",
    "def get_sinusoidal(n_seq, d_model):\n",
    "  '''\n",
    "  Args:\n",
    "      n_seq: sequence 길이 (=한 문장 내 토큰 개수)\n",
    "      d_model: (=512)\n",
    "  '''\n",
    "  def cal_angle(i_seq, i_dmodel):\n",
    "    return i_seq / np.power(10000, 2 * (i_dmodel // 2) / d_model)\n",
    "\n",
    "  def get_pos_enc(i_seq):\n",
    "    return [cal_angle(i_seq, i_dmodel) for i_dmodel in range(d_model)]\n",
    "\n",
    "  pos_enc_table = np.array([get_pos_enc(i_seq) for i_seq in range(n_seq)])\n",
    "  pos_enc_table[:, 0::2] = np.sin(pos_enc_table[:, 0::2]) # even idx\n",
    "  pos_enc_table[:, 1::2] = np.cos(pos_enc_table[:, 1::2]) # odd idx\n",
    "\n",
    "  return pos_enc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "wDLdcwFstORI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.conv1 = nn.Conv1d(in_channels=self.config[\"d_model\"], out_channels=self.config[\"d_ff\"], kernel_size=1)\n",
    "    self.conv2 = nn.Conv1d(in_channels=self.config[\"d_ff\"], out_channels=self.config[\"d_model\"], kernel_size=1)\n",
    "    self.active = F.relu\n",
    "    self.dropout = nn.Dropout(self.config[\"dropout\"])\n",
    "\n",
    "  # inputs: (batch_size, n_seq, d_model)\n",
    "  def forward(self, inputs):\n",
    "    # (batch_size, n_seq, d_model) -> (batch_size, d_model, n_seq) -> (batch_size, d_ff, n_seq)\n",
    "    output = self.active(self.conv1(inputs.transpose(1,2)))\n",
    "    # (batch_size, d_ff, n_seq) -> (batch_size, d_model, n_seq) -> (batch_size, n_seq, d_model)\n",
    "    output = self.conv2(output).transpose(1,2)\n",
    "    output = self.dropout(output)\n",
    "    # output: (batch_size, n_seq, d_model)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Af74qOF-tQOy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention pad mask\n",
    "def get_attn_pad_mask(query, key, i_pad):\n",
    "  '''\n",
    "  Args:\n",
    "      query: query(Q) (batch_size, 문장 내 토큰 개수)\n",
    "      key: key(K) (batch_size, 문장 내 토큰 개수)\n",
    "      * 전처리 했으므로 배치 내 토큰 개수 동일\n",
    "      i_pad: padding 인덱스 (=0)\n",
    "  '''\n",
    "  batch_size, len_q = query.size()\n",
    "  batch_size, len_k = key.size()\n",
    "  # (batch_size, len_q, len_k)\n",
    "  mask = key.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
    "  return mask\n",
    "\n",
    "\n",
    "# attention decoder mask\n",
    "def get_attn_decoder_mask(seq):\n",
    "  '''\n",
    "  Args:\n",
    "      seq: (batch_size, 문장 내 토큰 개수)\n",
    "  '''\n",
    "  mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "  # (batch_size, len_seq, len_seq)\n",
    "  mask = mask.triu(diagonal=1)\n",
    "  return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "_nfpAygWtRm2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.dropout = nn.Dropout(self.config[\"dropout\"])\n",
    "    self.scale = 1 / (self.config[\"d_h\"] ** 0.5)\n",
    "\n",
    "  def forward(self, Q, K, V, attn_mask):\n",
    "    '''\n",
    "    Args:\n",
    "        Q: (batch_size, h, len_q, d_h)\n",
    "        K: (batch_size, h, len_k, d_h)\n",
    "        V: (batch_size, h, len_v, d_h)\n",
    "        attn_mask: (batch_size, h, len_q, len_k)\n",
    "    '''\n",
    "    # (batch_size, h, len_q, len_k)\n",
    "    affinities = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "    affinities.masked_fill_(attn_mask, -1e9)\n",
    "    # (batch_size, h, len_q, len_k)\n",
    "    attn_weights = nn.Softmax(dim=-1)(affinities)\n",
    "    attn_weights = self.dropout(attn_weights)\n",
    "    # (batch_size, h, len_q, d_h)\n",
    "    output = torch.matmul(attn_weights, V)\n",
    "    # (batch_size, h, len_q, d_h), (batch_size, h, len_q, len_k)\n",
    "    return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "bczOeTv-tTFe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.W_Q = nn.Linear(self.config['d_model'], self.config['h'] * self.config['d_h'])\n",
    "    self.W_K = nn.Linear(self.config['d_model'], self.config['h'] * self.config['d_h'])\n",
    "    self.W_V = nn.Linear(self.config['d_model'], self.config['h'] * self.config['d_h'])\n",
    "    self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "    self.linear = nn.Linear(self.config['h'] * self.config['d_h'], self.config['d_model'])\n",
    "    self.dropout = nn.Dropout(self.config['dropout'])\n",
    "\n",
    "  def forward(self, Q, K, V, attn_mask):\n",
    "    '''\n",
    "    Args:\n",
    "        Q: (batch_size, len_q, d_model)\n",
    "        K: (batch_size, len_q, d_model)\n",
    "        V: (batch_size, len_q, d_model)\n",
    "        attn_mask: (batch_size, len_q, len_k)\n",
    "    '''\n",
    "    # linearly project the queries, keys and values\n",
    "    # (batch_size, len_q, d_model) * (d_model, h * d_h) = (batch_size, len_q, h * d_h)\n",
    "    # -> (batch_size, len_q, h, d_h)\n",
    "    # -> (batch_size, h, len_q, d_h)\n",
    "    pjted_Q = self.W_Q(Q).view(self.config['batch_size'], -1, self.config['h'], self.config['d_h']).transpose(1,2)\n",
    "    pjted_K = self.W_K(K).view(self.config['batch_size'], -1, self.config['h'], self.config['d_h']).transpose(1,2)\n",
    "    pjted_V = self.W_V(V).view(self.config['batch_size'], -1, self.config['h'], self.config['d_h']).transpose(1,2)\n",
    "    # (batch_size, len_q, len_k) -> (batch_size, h, len_q, len_k)\n",
    "    attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config['h'], 1, 1)\n",
    "    # scaled dot product attention\n",
    "    # (batch_size, h, len_q, d_h), (batch_size, h, len_q, len_k)\n",
    "    context, attn_weights = self.scaled_dot_attn(pjted_Q, pjted_K, pjted_V, attn_mask)\n",
    "    # concat\n",
    "    # (batch_size, h, len_q, d_h) -> (batch_size, len_q, h * d_h)\n",
    "    context= context.transpose(1, 2).contiguous().view(self.config['batch_size'], -1, self.config['h'] * self.config['d_h'])\n",
    "    # linear\n",
    "    # (batch_size, len_q, h * d_h) * (h * d_h, d_model)\n",
    "    # -> (batch_size, len_q, d_model)\n",
    "    output = self.linear(context)\n",
    "    output = self.dropout(output)\n",
    "    # (batch_size, len_q, d_model), (batch_size, h, len_q, len_k)\n",
    "    return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "X2h51mD5tVeS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder layer\n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.self_attn = MultiHeadAttention(self.config)\n",
    "    self.layer_norm1 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "    self.ffn = FFN(self.config)\n",
    "    self.layer_norm2 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "\n",
    "  '''\n",
    "  Args:\n",
    "      inputs: (batch_size, len_seq, d_model)\n",
    "      attn_mask: (batch_size, len_q, len_k)\n",
    "  '''\n",
    "  def forward(self, inputs, attn_mask):\n",
    "    # (batch_size, len_q, d_model), (batch_size, h, len_q, len_k)\n",
    "    attn_output, attn_weights = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
    "    # (batch_size, len_q, d_model)\n",
    "    attn_output = self.layer_norm1(inputs + attn_output)\n",
    "    # (batch_size, len_q, d_model)\n",
    "    ffn_output = self.ffn(attn_output)\n",
    "    # (batch_size, len_q, d_model)\n",
    "    ffn_output = self.layer_norm2(ffn_output + attn_output)\n",
    "    # (batch_size, len_q, d_model), (batch_size, h, len_q, len_k)\n",
    "    return ffn_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "yYRWsF2Dth-I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.enc_emb = nn.Embedding(self.config[\"n_enc_vocab\"], self.config[\"d_model\"])\n",
    "    pos_enc_table = torch.FloatTensor(get_sinusoidal(self.config[\"n_enc_seq\"] + 1, self.config[\"d_model\"]))\n",
    "    self.pos_emb = nn.Embedding.from_pretrained(pos_enc_table, freeze=True)\n",
    "\n",
    "    self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config[\"n_layer\"])])\n",
    "\n",
    "  '''\n",
    "  Args\n",
    "      inputs: (batch_size, len_seq)\n",
    "  '''\n",
    "  def forward(self, inputs):\n",
    "    # (batch_size, len_enc_seq)\n",
    "    positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
    "    pos_mask = inputs.eq(self.config[\"i_pad\"])\n",
    "    positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "    # (batch_size, len_enc_seq, d_model)\n",
    "    output = self.enc_emb(inputs) + self.pos_emb(positions)\n",
    "\n",
    "    # (batch_size, len_enc_seq, len_enc_seq)\n",
    "    attn_mask = get_attn_pad_mask(inputs, inputs, self.config[\"i_pad\"])\n",
    "\n",
    "    attn_weights_history = list([])\n",
    "    for layer in self.layers:\n",
    "      # (batch_size, len_enc_seq, d_model), (batch_size, h, len_enc_seq, len_enc_seq)\n",
    "      output, attn_weights = layer(output, attn_mask)\n",
    "      attn_weights_history.append(attn_weights)\n",
    "\n",
    "    # (batch_size, len_enc_seq, d_model), [(batch_size, h, len_enc_seq, len_enc_seq)]\n",
    "    return output, attn_weights_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "kuG4-Jn80FkD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.self_attn = MultiHeadAttention(self.config)\n",
    "    self.layer_norm1 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "    self.enc_dec_attn = MultiHeadAttention(self.config)\n",
    "    self.layer_norm2 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "    self.ffn = FFN(self.config)\n",
    "    self.layer_norm3 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "\n",
    "  '''\n",
    "  Args:\n",
    "      dec_inputs: (batch_size, len_seq, d_model)\n",
    "      enc_outputs: (batch_size, len_enc_seq, d_model)\n",
    "      self_attn_mask: (batch_size, len_dec_seq, len_dec_seq)\n",
    "      enc_dec_attn_mask: (batch_size, len_dec_seq, len_enc_seq)\n",
    "  '''\n",
    "  def forward(self, dec_inputs, enc_outputs, self_attn_mask, enc_dec_attn_mask):\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq)\n",
    "    self_attn_output, self_attn_weights = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
    "    self_attn_output = self.layer_norm1(dec_inputs + self_attn_output)\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "    enc_dec_attn_output, enc_dec_attn_weights = self.enc_dec_attn(self_attn_output, enc_outputs, enc_outputs, enc_dec_attn_mask)\n",
    "    enc_dec_attn_output = self.layer_norm2(self_attn_output + enc_dec_attn_output)\n",
    "    # (batch_size, len_dec_seq, d_model)\n",
    "    ffn_output = self.ffn(enc_dec_attn_output)\n",
    "    ffn_output = self.layer_norm3(enc_dec_attn_output + ffn_output)\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "    return ffn_output, self_attn_weights, enc_dec_attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "uDhoza9D8w4T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.dec_emb = nn.Embedding(self.config[\"n_dec_vocab\"], self.config[\"d_model\"])\n",
    "    pos_enc_table = torch.FloatTensor(get_sinusoidal(self.config[\"n_dec_seq\"] + 1, self.config[\"d_model\"]))\n",
    "    self.pos_emb = nn.Embedding.from_pretrained(pos_enc_table, freeze=True)\n",
    "\n",
    "    self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config[\"n_layer\"])])\n",
    "\n",
    "  '''\n",
    "  Args:\n",
    "      dec_inputs: (batch_size, len_dec_seq, d_model)\n",
    "      enc_inputs: (batch_size, len_enc_seq, d_model)\n",
    "      enc_outputs: (batch_size, len_enc_seq, d_model)\n",
    "  '''\n",
    "  def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "    # (batch_size, len_enc_seq)\n",
    "    positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
    "    pos_mask = dec_inputs.eq(self.config[\"i_pad\"])\n",
    "    positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "    # (batch_size, n_dec_seq, d_model)\n",
    "    dec_output = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
    "\n",
    "    # (batch_size, len_dec_seq, len_dec_seq)\n",
    "    attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config[\"i_pad\"])\n",
    "    # (batch_size, len_dec_seq, len_dec_seq)\n",
    "    attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
    "    # (batch_size, len_dec_seq, len_dec_seq)\n",
    "    self_attn_mask = torch.gt((attn_pad_mask + attn_decoder_mask), 0)\n",
    "    # (batch_size, len_dec_seq, len_enc_seq)\n",
    "    enc_dec_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config[\"i_pad\"])\n",
    "\n",
    "    self_attn_weights_history, enc_dec_attn_weights_history = list([]), list([])\n",
    "    for layer in self.layers:\n",
    "      # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "      output, self_attn_weights, enc_dec_attn_weights = layer(dec_output, enc_outputs, self_attn_mask, enc_dec_attn_mask)\n",
    "      self_attn_weights_history.append(self_attn_weights)\n",
    "      enc_dec_attn_weights_history.append(enc_dec_attn_weights)\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "    return output, self_attn_weights_history, enc_dec_attn_weights_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084880,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "WJoeFXf7ubwl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def returnExampleBatch():\n",
    "  cnt = 0\n",
    "  for [enc, dec] in loader:\n",
    "   if (cnt < 1):\n",
    "      return enc, dec\n",
    "   else:\n",
    "      break\n",
    "\n",
    "q, k = returnExampleBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1282,
     "status": "ok",
     "timestamp": 1701147086149,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Z6NXoidjugMa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_config[\"n_enc_seq\"] = q.size(1)\n",
    "tmp_config[\"n_dec_seq\"] = k.size(1)\n",
    "encoder = Encoder(tmp_config)\n",
    "decoder = Decoder(tmp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 312,
     "status": "ok",
     "timestamp": 1701147086456,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "QnOpB7_f128z",
    "outputId": "4375f8f5-631f-4730-9c78-63345adb7474",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3198,  1.2951, -1.3993,  ...,  1.0435, -1.2243,  0.1747],\n",
       "         [ 1.3494,  0.3532, -1.1673,  ..., -0.5503,  0.7476,  0.9111],\n",
       "         [ 0.8210,  0.0699,  0.6038,  ...,  2.5298,  0.4141, -0.2870],\n",
       "         ...,\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497]],\n",
       "\n",
       "        [[ 0.4927, -0.2389, -0.9813,  ..., -0.7799, -0.1842, -0.6516],\n",
       "         [-0.4706,  1.0932, -0.8204,  ..., -0.1230, -0.8389,  0.0110],\n",
       "         [-0.2819, -1.6732, -0.8879,  ...,  1.0908, -1.8238,  0.2782],\n",
       "         ...,\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497]],\n",
       "\n",
       "        [[ 1.6670, -1.5437, -0.7686,  ...,  0.6676,  0.5874, -2.2881],\n",
       "         [ 0.2686,  1.6338, -1.7464,  ...,  2.2345, -1.1956, -0.8890],\n",
       "         [-0.6229,  1.3066, -1.4920,  ...,  1.0949, -0.5926, -0.6741],\n",
       "         ...,\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.1567, -0.0776,  0.3011,  ..., -1.3620, -1.3399, -1.0313],\n",
       "         [-1.1026,  0.1146,  0.2792,  ...,  0.3598,  0.8091, -1.4299],\n",
       "         [ 1.3372, -1.3453,  1.5011,  ..., -1.7187,  0.9258,  0.3022],\n",
       "         ...,\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497]],\n",
       "\n",
       "        [[-0.3198,  1.2951, -1.3993,  ...,  1.0435, -1.2243,  0.1747],\n",
       "         [ 0.0945, -0.8612, -1.6856,  ..., -1.3831, -0.1803,  1.2782],\n",
       "         [ 1.9852,  0.5305,  1.0386,  ..., -1.2737,  0.5628, -0.4076],\n",
       "         ...,\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497]],\n",
       "\n",
       "        [[-1.3303,  0.7313,  1.0023,  ...,  1.2644, -0.6041, -1.4020],\n",
       "         [-0.4287, -0.1351,  0.3351,  ..., -0.0480,  0.1998,  0.8221],\n",
       "         [ 0.7341, -0.1398, -0.7311,  ..., -0.2728, -0.2061,  2.1717],\n",
       "         ...,\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497],\n",
       "         [-0.1503,  0.7005,  0.1998,  ...,  0.9149, -0.3655, -2.8497]]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_emb = nn.Embedding(tmp_config[\"n_dec_vocab\"], tmp_config[\"d_model\"])\n",
    "dec_emb(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 31032,
     "status": "ok",
     "timestamp": 1701147117484,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "4fDjeCNF21ey",
    "tags": []
   },
   "outputs": [],
   "source": [
    "enc_output, enc_attn_weights_history = encoder(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "y2uwWiZuumXy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_output, self_attn_weights_history, enc_dec_attn_weights_history = decoder(k, q, enc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6147,  0.2046, -0.5662,  ...,  0.4568,  0.7345, -0.0306],\n",
       "         [-2.1806, -1.8684, -0.7533,  ...,  0.2911,  0.5270, -0.4030],\n",
       "         [-0.0437, -1.8510, -0.2617,  ...,  0.8317,  0.6737, -0.4886],\n",
       "         ...,\n",
       "         [-1.1348,  1.0266, -1.9929,  ...,  0.9832, -0.1817,  1.6928],\n",
       "         [-1.1243,  0.9976, -1.9546,  ...,  0.9526, -0.1631,  1.6141],\n",
       "         [-1.2238,  1.0436, -2.0170,  ...,  0.9551, -0.2663,  1.7579]],\n",
       "\n",
       "        [[ 0.1220, -1.9133, -0.6859,  ...,  1.6220, -0.4513,  1.1376],\n",
       "         [-0.3976, -0.3339, -0.6933,  ..., -0.4622, -0.7073,  1.1712],\n",
       "         [-0.7005, -0.5292, -1.0053,  ..., -0.1962, -0.3625, -1.0097],\n",
       "         ...,\n",
       "         [-0.7120,  1.1325, -2.0580,  ...,  0.8775, -0.8116,  1.5938],\n",
       "         [-0.9712,  1.2309, -1.9925,  ...,  0.7699, -0.4765,  1.6661],\n",
       "         [-0.7355,  1.0696, -1.4077,  ...,  0.8887, -0.3985,  1.6437]],\n",
       "\n",
       "        [[-0.2350, -0.3345, -1.1349,  ...,  0.9967,  0.3326, -1.3287],\n",
       "         [ 0.3488, -2.0294, -0.2325,  ...,  0.7564, -0.5622,  0.6161],\n",
       "         [ 0.0033, -1.6360, -0.1464,  ...,  1.0090, -0.5710,  0.1613],\n",
       "         ...,\n",
       "         [-1.0652,  1.1538, -1.8968,  ...,  0.9672, -0.3139,  1.9012],\n",
       "         [-1.1073,  1.1887, -1.6582,  ...,  0.9985, -0.3789,  1.8382],\n",
       "         [-1.1180,  0.7494, -1.7311,  ...,  0.9305, -0.1854,  1.8133]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-2.0885,  0.1923, -0.6462,  ...,  1.1604,  1.3979,  0.5783],\n",
       "         [-0.5581, -1.1162, -0.1429,  ..., -0.2926,  0.1244, -0.3949],\n",
       "         [-0.6028, -1.7852, -1.1464,  ...,  2.6134,  0.8745,  1.3155],\n",
       "         ...,\n",
       "         [-1.0506,  0.7863, -1.9364,  ...,  0.9046, -0.4760,  1.3657],\n",
       "         [-0.9123,  0.8747, -2.1420,  ...,  0.9673, -0.3151,  1.2875],\n",
       "         [-1.0548,  0.8263, -2.0565,  ...,  0.9443, -0.4651,  1.6007]],\n",
       "\n",
       "        [[-0.6403, -0.2955, -0.3522,  ...,  0.7878,  0.8114,  0.2704],\n",
       "         [-0.5017, -0.5546, -1.2208,  ...,  0.9213, -1.0892,  1.2553],\n",
       "         [ 0.7676, -2.4111, -1.9540,  ...,  0.3217,  0.4411,  1.5938],\n",
       "         ...,\n",
       "         [-0.9966,  1.0487, -1.9246,  ...,  0.9806, -0.2228,  1.7748],\n",
       "         [-1.0188,  0.6225, -1.9825,  ...,  0.8691, -0.6452,  1.8066],\n",
       "         [-0.9537,  1.0676, -1.3293,  ...,  0.9720, -0.2359,  1.8434]],\n",
       "\n",
       "        [[-0.5468,  0.5619, -0.3860,  ...,  1.4413, -1.8935,  0.3977],\n",
       "         [ 0.8579,  0.4473,  0.2106,  ...,  1.9588, -1.4161,  0.3732],\n",
       "         [ 0.3150, -1.5563, -0.2801,  ...,  1.2004,  0.5607,  1.2341],\n",
       "         ...,\n",
       "         [-0.8213,  0.7848, -1.3581,  ...,  0.9755, -0.9687,  1.8288],\n",
       "         [-0.9524,  0.6217, -1.7247,  ...,  1.0370, -0.3892,  1.8550],\n",
       "         [-0.9061,  0.8245, -1.9096,  ...,  0.9926, -0.3464,  1.7660]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 78, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(self_attn_weights_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8, 78, 78])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attn_weights_history[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc_dec_attn_weights_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8, 78, 92])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_dec_attn_weights_history[0].size()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPsoty5ZvCk1uE7m9MmeNpy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dnkim419",
   "language": "python",
   "name": "dnkim419"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGyXRPF1TtMf",
        "outputId": "1978c3bf-475e-4cfa-f8a6-114e0102e149"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/backup\n"
          ]
        }
      ],
      "source": [
        " # This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "FOLDERNAME = 'backup'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
        "\n",
        "# Change dariectory to current folder\n",
        "%cd /content/drive/MyDrive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JuieQwL-dOnl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eP7fFn3mOrAY",
        "outputId": "a6b3cdb4-7159-4433-955d-88372f95adc6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "de_vocab_file = 'de.model'\n",
        "en_vocab_file = 'en.model'\n",
        "\n",
        "de_vocab = spm.SentencePieceProcessor()\n",
        "en_vocab = spm.SentencePieceProcessor()\n",
        "\n",
        "# de, en vocab 로드\n",
        "de_vocab.load(de_vocab_file)\n",
        "en_vocab.load(en_vocab_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdhBA0v8Phid",
        "outputId": "c03779cc-fd0e-47ef-ac60-a2058eee6d21"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "fwpHN7XZPnmT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ym4mYsygN1OR"
      },
      "outputs": [],
      "source": [
        "# data.py\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.data.distributed import DistributedSampler\n",
        "\n",
        "# mt Dataset\n",
        "class MtDataset(Dataset):\n",
        "  def __init__(self, src_vocab, trg_vocab, df, src_name, trg_name):\n",
        "    self.src_vocab  = src_vocab\n",
        "    self.trg_vocab = trg_vocab\n",
        "    self.src_train = []\n",
        "    self.trg_train = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "      src_line = row[src_name]\n",
        "      trg_line = row[trg_name]\n",
        "      if type(src_line) != str or type(trg_line) != str:\n",
        "        continue\n",
        "      # src 문장, trg 문장 각각 tokenize\n",
        "      self.src_train.append(src_vocab.encode_as_ids(src_line))\n",
        "      self.trg_train.append(trg_vocab.encode_as_ids(trg_line))\n",
        "\n",
        "  def __len__(self):\n",
        "    assert len(self.src_train) == len(self.trg_train)\n",
        "    return len(self.src_train)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return (torch.tensor(self.src_train[idx]), torch.tensor(self.trg_train[idx]))\n",
        "\n",
        "\n",
        "# mt data collate_fn\n",
        "# 배치 단위로 데이터 처리\n",
        "def mt_collate_fn(inputs):\n",
        "  enc_inputs, dec_inputs = list(zip(*inputs)) # to do\n",
        "\n",
        "  # 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0) 추가\n",
        "  enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True)\n",
        "  dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True)\n",
        "\n",
        "  batch = [\n",
        "      enc_inputs,\n",
        "      dec_inputs\n",
        "  ]\n",
        "\n",
        "  return batch # DataLoader iterate 할 때 return됨\n",
        "\n",
        "\n",
        "# DataLoader\n",
        "def build_mt_data_loader(src_vocab, trg_vocab, df, src_name, trg_name, args, shuffle=True):\n",
        "  # Dataset 생성\n",
        "  dataset = MtDataset(src_vocab, trg_vocab, df, src_name, trg_name)\n",
        "  if 1 < args['n_gpu'] and shuffle:\n",
        "    sampler = DistributedSampler(dataset)\n",
        "    loader = DataLoader(dataset, batch_size=args['batch'], sampler=sampler, collate_fn=mt_collate_fn)\n",
        "  else:\n",
        "    sampler = None\n",
        "    loader = DataLoader(dataset, batch_size=args['batch'], sampler=sampler, shuffle=shuffle, collate_fn=mt_collate_fn)\n",
        "\n",
        "  return loader, sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Iv5AeRwVONjs"
      },
      "outputs": [],
      "source": [
        "args = {\n",
        "    'n_gpu': 1,\n",
        "    'batch': 256\n",
        "}\n",
        "\n",
        "loader, sampler = build_mt_data_loader(en_vocab, de_vocab, train_df, 'en', 'de', args)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnt = 0\n",
        "\n",
        "for [enc, dec] in loader:\n",
        "  if (cnt < 1):\n",
        "    print(dec)\n",
        "    print(len(dec))\n",
        "    cnt+= 1\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gnpJqd2FnTI",
        "outputId": "b4cb2f6e-4ed0-4944-ad99-7943176e4815"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2917,  249,  269,  ...,    0,    0,    0],\n",
            "        [2852,   95,  138,  ...,    0,    0,    0],\n",
            "        [ 118,  198,   18,  ...,    0,    0,    0],\n",
            "        ...,\n",
            "        [ 934,  615,  153,  ...,    0,    0,    0],\n",
            "        [1954,  200, 3551,  ...,    0,    0,    0],\n",
            "        [ 145,  850, 1287,  ...,    0,    0,    0]])\n",
            "256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zrWPcckqTvwW"
      },
      "outputs": [],
      "source": [
        "# Sinusoidal position representations\n",
        "def get_sinusoidal(n_seq, d_model):\n",
        "  '''\n",
        "  Args:\n",
        "      n_seq: sequence 길이 (=한 문장 내 토큰 개수)\n",
        "      d_model: (=512)\n",
        "  '''\n",
        "  def cal_angle(i_seq, i_dmodel):\n",
        "    return i_seq / np.power(10000, 2 * (i_dmodel // 2) / d_model)\n",
        "\n",
        "  def get_pos_enc(i_seq):\n",
        "    return [cal_angle(i_seq, i_dmodel) for i_dmodel in range(d_model)]\n",
        "\n",
        "  pos_enc_table = np.array([get_pos_enc(i_seq) for i_seq in range(n_seq)])\n",
        "  pos_enc_table[:, 0::2] = np.sin(pos_enc_table[:, 0::2]) # even idx\n",
        "  pos_enc_table[:, 1::2] = np.cos(pos_enc_table[:, 1::2]) # odd idx\n",
        "\n",
        "  return pos_enc_table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "78fzO1qfdVmg"
      },
      "outputs": [],
      "source": [
        "# encoder\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.enc_emb = nn.Embedding(self.config[\"n_enc_vocab\"], self.config[\"d_model\"])\n",
        "    pos_enc_table = torch.FloatTensor(get_sinusoidal(self.config[\"n_enc_seq\"], self.config[\"d_model\"]))\n",
        "    self.pos_emb = nn.Embedding.from_pretrained(pos_enc_table, freeze=True)\n",
        "\n",
        "    # to do: EncoderLayer\n",
        "\n",
        "  # to do: forward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "h__Gwxos5t1o"
      },
      "outputs": [],
      "source": [
        "tmp_config = {\n",
        "    \"n_enc_vocab\": 8000, # tmp\n",
        "    \"n_enc_seq\": 80, # tmp\n",
        "    \"d_model\": 512,\n",
        "    \"d_ff\": 2048,\n",
        "    \"dropout\": 0.1,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gzH7qce96DJ4",
        "outputId": "5526793a-2b9c-42fc-c564-ae51b570c79e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (enc_emb): Embedding(8000, 512)\n",
              "  (pos_emb): Embedding(80, 512)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "Encoder(tmp_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yoOKtYh6mog",
        "outputId": "a95dce33-e23f-4d98-b46c-0d4209d3f356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.8210, -0.0443, -2.0217,  ..., -0.1930, -0.1446, -0.1005],\n",
            "        [ 0.7124,  0.9599,  0.1027,  ..., -0.2614,  1.2562, -1.2971],\n",
            "        [-0.5088,  0.2574,  0.9511,  ..., -0.7704, -0.6936, -1.3515],\n",
            "        ...,\n",
            "        [ 0.0284, -1.7049,  0.7069,  ...,  0.1039, -0.6297, -1.7581],\n",
            "        [-0.9041,  0.3820, -0.5600,  ...,  0.8880,  1.3087,  1.7325],\n",
            "        [-0.7475, -0.7080,  1.1771,  ...,  0.9510,  1.1564, -2.3144]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(Encoder(tmp_config).enc_emb.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5afy7-DI7fnx",
        "outputId": "1e18b408-b46d-4ea1-c531-93c2fa672a0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n",
            "          0.0000e+00,  1.0000e+00],\n",
            "        [ 8.4147e-01,  5.4030e-01,  8.2186e-01,  ...,  1.0000e+00,\n",
            "          1.0366e-04,  1.0000e+00],\n",
            "        [ 9.0930e-01, -4.1615e-01,  9.3641e-01,  ...,  1.0000e+00,\n",
            "          2.0733e-04,  1.0000e+00],\n",
            "        ...,\n",
            "        [ 9.9952e-01, -3.0975e-02, -8.9979e-01,  ...,  9.9997e-01,\n",
            "          7.9820e-03,  9.9997e-01],\n",
            "        [ 5.1398e-01, -8.5780e-01, -1.5400e-01,  ...,  9.9996e-01,\n",
            "          8.0856e-03,  9.9997e-01],\n",
            "        [-4.4411e-01, -8.9597e-01,  7.2432e-01,  ...,  9.9996e-01,\n",
            "          8.1893e-03,  9.9997e-01]])\n"
          ]
        }
      ],
      "source": [
        "print(Encoder(tmp_config).pos_emb.weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mncRBQu588gX"
      },
      "outputs": [],
      "source": [
        "class FFN(nn.Module):\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self.config = config\n",
        "\n",
        "    self.conv1 = nn.Conv1d(in_channels=self.config[\"d_model\"], out_channels=self.config[\"d_ff\"], kernel_size=1)\n",
        "    self.conv2 = nn.Conv1d(in_channels=self.config[\"d_ff\"], out_channels=self.config[\"d_model\"], kernel_size=1)\n",
        "    self.active = F.relu\n",
        "    self.dropout = nn.Dropout(self.config[\"dropout\"])\n",
        "\n",
        "  # inputs: (batch, n_seq, d_model)\n",
        "  def forward(self, inputs):\n",
        "    # (batch, n_seq, d_model) -> (batch, d_model, n_seq) -> (batch, d_ff, n_seq)\n",
        "    output = self.active(self.conv1(inputs.transpose(1,2)))\n",
        "    # (batch, d_ff, n_seq) -> (batch, d_model, n_seq) -> (batch, n_seq, d_model)\n",
        "    output = self.conv2(output).transpose(1,2)\n",
        "    output = self.dropout(output)\n",
        "    # output: (batch, n_seq, d_model)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jTTNw2ooNnrN"
      },
      "outputs": [],
      "source": [
        "ffn = FFN(tmp_config)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_emb = nn.Embedding(tmp_config[\"n_enc_vocab\"], tmp_config[\"d_model\"])"
      ],
      "metadata": {
        "id": "Q6YdfOf6Rmkt"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def returnExampleBatch():\n",
        "  cnt = 0\n",
        "  for [enc, dec] in loader:\n",
        "   if (cnt < 1):\n",
        "      return dec\n",
        "   else:\n",
        "      break\n",
        "\n",
        "dec = returnExampleBatch()"
      ],
      "metadata": {
        "id": "tfe9RbsZlvP9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uAxTSxpmwqV",
        "outputId": "db6e102c-6045-4855-d48f-9a586c84a6c8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 190,  253,   73,  ...,    0,    0,    0],\n",
              "        [ 180, 3355,  226,  ...,    0,    0,    0],\n",
              "        [3754, 2520,   95,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 255,   79,  617,  ...,    0,    0,    0],\n",
              "        [ 667,  251,  125,  ...,    0,    0,    0],\n",
              "        [ 551, 5833, 3959,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_emb(dec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pBAWFaUivNW_",
        "outputId": "1d68dae1-4468-4ddd-a65c-29939c1f211c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0415,  0.8546, -1.0981,  ..., -0.4615, -0.8794, -0.8114],\n",
              "         [-1.1174, -0.2138, -0.4115,  ...,  0.5420, -1.4181,  0.8671],\n",
              "         [-0.4778,  0.5613,  0.1543,  ..., -0.3974,  0.5664, -0.8370],\n",
              "         ...,\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411]],\n",
              "\n",
              "        [[ 0.9699,  1.3379,  0.5686,  ..., -1.5771, -0.0311, -0.8929],\n",
              "         [ 0.3331,  0.3030, -1.5208,  ..., -0.4909,  0.9014, -0.3108],\n",
              "         [ 0.2615, -1.4597,  1.2918,  ..., -0.7148, -0.9845, -2.3205],\n",
              "         ...,\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411]],\n",
              "\n",
              "        [[-0.4639, -0.7064, -0.0405,  ..., -0.1532,  1.0295, -0.2411],\n",
              "         [ 1.8425, -1.4005,  0.0723,  ...,  0.9323, -0.5105, -1.2091],\n",
              "         [-0.2377, -1.5298,  2.1385,  ..., -0.2962, -0.4548, -0.5287],\n",
              "         ...,\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 1.2165, -0.8068, -0.6884,  ..., -0.9741,  1.5973, -0.8044],\n",
              "         [ 0.0402, -1.3887, -0.2789,  ..., -0.8804,  0.4892,  1.2297],\n",
              "         [ 0.9706, -0.3470,  0.0041,  ...,  1.1038, -0.0687, -0.6266],\n",
              "         ...,\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411]],\n",
              "\n",
              "        [[ 0.0783, -0.9982, -0.7995,  ...,  0.2163, -0.1441, -1.1986],\n",
              "         [ 0.8300, -0.6586, -0.6274,  ..., -0.8020,  1.4217, -0.2704],\n",
              "         [ 0.2089, -0.4502, -1.4897,  ..., -0.2288, -0.8278, -1.6140],\n",
              "         ...,\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411]],\n",
              "\n",
              "        [[-0.4658,  1.7258,  1.8074,  ...,  0.3956,  2.3919,  2.4048],\n",
              "         [ 0.8814, -2.3950,  0.9615,  ..., -1.0623, -1.0750,  0.0542],\n",
              "         [-0.3316, -0.2136,  1.5078,  ..., -1.1188,  0.8118, -0.8015],\n",
              "         ...,\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411],\n",
              "         [-1.2571,  0.3741, -0.4790,  ..., -0.1764,  0.2920, -0.6411]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc_emb(dec).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSR9rImK0iN3",
        "outputId": "83943b4a-2212-4ac9-9d8b-cb1b3e40b278"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 99, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ffn(enc_emb(dec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaBG-8SZ38_a",
        "outputId": "1c5bcaa4-4bf3-41bb-f51e-bcb2e4fad244"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.0621,  0.1647,  0.0645,  ...,  0.4189, -0.0120,  0.1492],\n",
              "         [ 0.0017,  0.0761,  0.0288,  ..., -0.2232, -0.0000,  0.3664],\n",
              "         [-0.2253,  0.0000,  0.0461,  ...,  0.0597, -0.3720,  0.2997],\n",
              "         ...,\n",
              "         [ 0.1333, -0.0858, -0.0000,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.0000,  0.1680]],\n",
              "\n",
              "        [[ 0.1283, -0.1453, -0.0175,  ...,  0.2233, -0.1305, -0.3449],\n",
              "         [-0.2191,  0.1587, -0.1020,  ...,  0.0289,  0.2410,  0.5558],\n",
              "         [-0.3985, -0.1711, -0.1567,  ...,  0.1896, -0.4181,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1333, -0.0858, -0.0000,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.0000,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680]],\n",
              "\n",
              "        [[ 0.0702, -0.0319, -0.1256,  ..., -0.0000,  0.1472,  0.0247],\n",
              "         [-0.0154,  0.2240, -0.3654,  ...,  0.0302, -0.3098,  0.1829],\n",
              "         [ 0.0762,  0.2045, -0.1300,  ..., -0.4778, -0.5376,  0.0000],\n",
              "         ...,\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.0000],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.0000,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.0000]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0000,  0.2810,  0.2185,  ...,  0.1241,  0.1681, -0.0404],\n",
              "         [-0.1514,  0.0492, -0.0594,  ...,  0.2091, -0.3329, -0.2372],\n",
              "         [-0.0408, -0.2595,  0.0377,  ..., -0.1195,  0.1826,  0.4159],\n",
              "         ...,\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.0000,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.0000,  0.4001,  0.1680]],\n",
              "\n",
              "        [[ 0.2718,  0.0188, -0.1776,  ..., -0.1556, -0.0336, -0.0485],\n",
              "         [ 0.0203,  0.4111, -0.0745,  ..., -0.4889, -0.3173,  0.0000],\n",
              "         [ 0.1588,  0.0570,  0.3813,  ..., -0.4050,  0.2670, -0.4787],\n",
              "         ...,\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.0000, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680]],\n",
              "\n",
              "        [[-0.1685,  0.0623, -0.0000,  ..., -0.0979, -0.1165,  0.0735],\n",
              "         [ 0.0468,  0.0000, -0.1255,  ..., -0.2635, -0.0705,  0.3325],\n",
              "         [-0.2015,  0.5624, -0.3173,  ...,  0.0851,  0.2133,  0.1890],\n",
              "         ...,\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.1680],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.2197,  0.4001,  0.0000],\n",
              "         [ 0.1333, -0.0858, -0.1067,  ...,  0.0000,  0.4001,  0.1680]]],\n",
              "       grad_fn=<MulBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ffn(enc_emb(dec)).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqL2cMR84SUR",
        "outputId": "2284658f-f5ef-4505-b20d-5685eb0cd067"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 99, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
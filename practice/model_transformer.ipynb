{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4190,
     "status": "ok",
     "timestamp": 1701147007977,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "gLoHbtevs1rg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7687,
     "status": "ok",
     "timestamp": 1701147015651,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "xQXCZHKks4Ao",
    "outputId": "7d9bedd2-dcf6-4bcc-f052-ed60b355145a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\dmis\\anaconda3\\envs\\dnkim419\\lib\\site-packages (0.1.99)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1701147016529,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "KCYRI2rms596",
    "outputId": "517c382b-6384-43bd-b439-e36920360669",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "de_vocab_file = '../vocab/de.model'\n",
    "en_vocab_file = '../vocab/en.model'\n",
    "\n",
    "de_vocab = spm.SentencePieceProcessor()\n",
    "en_vocab = spm.SentencePieceProcessor()\n",
    "\n",
    "# de, en vocab 로드\n",
    "de_vocab.load(de_vocab_file)\n",
    "en_vocab.load(en_vocab_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3180,
     "status": "ok",
     "timestamp": 1701147019705,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "ZiDEcYc1s6aQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('../dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701147019705,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Ph47lkGws71E",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data.py\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "\n",
    "# mt Dataset\n",
    "class MtDataset(Dataset):\n",
    "  def __init__(self, src_vocab, trg_vocab, df, src_name, trg_name):\n",
    "    self.src_vocab  = src_vocab\n",
    "    self.trg_vocab = trg_vocab\n",
    "    self.src_train = []\n",
    "    self.trg_train = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "      src_line = row[src_name]\n",
    "      trg_line = row[trg_name]\n",
    "      if type(src_line) != str or type(trg_line) != str:\n",
    "        continue\n",
    "      # src 문장, trg 문장 각각 tokenize\n",
    "      self.src_train.append(src_vocab.encode_as_ids(src_line))\n",
    "      self.trg_train.append(trg_vocab.encode_as_ids(trg_line))\n",
    "\n",
    "  def __len__(self):\n",
    "    assert len(self.src_train) == len(self.trg_train)\n",
    "    return len(self.src_train)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return (torch.tensor(self.src_train[idx]), torch.tensor(self.trg_train[idx]))\n",
    "\n",
    "\n",
    "# mt data collate_fn\n",
    "# 배치 단위로 데이터 처리\n",
    "def mt_collate_fn(inputs):\n",
    "  enc_inputs, dec_inputs = list(zip(*inputs)) # to do\n",
    "\n",
    "  # 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0) 추가\n",
    "  enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True)\n",
    "  dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True)\n",
    "\n",
    "  batch = [\n",
    "      enc_inputs,\n",
    "      dec_inputs\n",
    "  ]\n",
    "\n",
    "  return batch # DataLoader iterate 할 때 return됨\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "def build_mt_data_loader(src_vocab, trg_vocab, df, src_name, trg_name, args, shuffle=True):\n",
    "  # Dataset 생성\n",
    "  dataset = MtDataset(src_vocab, trg_vocab, df, src_name, trg_name)\n",
    "  if 1 < args['n_gpu'] and shuffle:\n",
    "    sampler = DistributedSampler(dataset)\n",
    "    loader = DataLoader(dataset, batch_size=args['batch_size'], sampler=sampler, collate_fn=mt_collate_fn)\n",
    "  else:\n",
    "    sampler = None\n",
    "    loader = DataLoader(dataset, batch_size=args['batch_size'], sampler=sampler, shuffle=shuffle, collate_fn=mt_collate_fn)\n",
    "\n",
    "  return loader, sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701147019705,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "OstDP6dgs9oS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_config = {\n",
    "    \"n_gpu\": 1, #tmp\n",
    "    \"n_layer\": 6,\n",
    "    \"batch_size\": 256,\n",
    "    \"n_enc_vocab\": 8000, # tmp\n",
    "    \"n_dec_vocab\": 8000, # tmp\n",
    "    \"n_enc_seq\": 80, # tmp\n",
    "    \"n_dec_seq\": 80, # tmp\n",
    "    \"d_model\": 512,\n",
    "    \"d_ff\": 2048,\n",
    "    \"h\": 8,\n",
    "    \"d_h\": 64,\n",
    "    \"dropout\": 0.1,\n",
    "    \"layer_norm_epsilon\": 1e-12,\n",
    "    \"i_pad\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 65175,
     "status": "ok",
     "timestamp": 1701147084878,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "MXapKd_Ms_EI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    'n_gpu': tmp_config['n_gpu'],\n",
    "    'batch_size': tmp_config['batch_size'],\n",
    "}\n",
    "\n",
    "loader, sampler = build_mt_data_loader(en_vocab, de_vocab, train_df, 'en', 'de', args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Duu2oIKEtM-G",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sinusoidal position representations\n",
    "def get_sinusoidal(n_seq, d_model):\n",
    "  '''\n",
    "  Args:\n",
    "      n_seq: sequence 길이 (=한 문장 내 토큰 개수)\n",
    "      d_model: (=512)\n",
    "  '''\n",
    "  def cal_angle(i_seq, i_dmodel):\n",
    "    return i_seq / np.power(10000, 2 * (i_dmodel // 2) / d_model)\n",
    "\n",
    "  def get_pos_enc(i_seq):\n",
    "    return [cal_angle(i_seq, i_dmodel) for i_dmodel in range(d_model)]\n",
    "\n",
    "  pos_enc_table = np.array([get_pos_enc(i_seq) for i_seq in range(n_seq)])\n",
    "  pos_enc_table[:, 0::2] = np.sin(pos_enc_table[:, 0::2]) # even idx\n",
    "  pos_enc_table[:, 1::2] = np.cos(pos_enc_table[:, 1::2]) # odd idx\n",
    "\n",
    "  return pos_enc_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "wDLdcwFstORI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class FFN(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.conv1 = nn.Conv1d(in_channels=self.config[\"d_model\"], out_channels=self.config[\"d_ff\"], kernel_size=1)\n",
    "    self.conv2 = nn.Conv1d(in_channels=self.config[\"d_ff\"], out_channels=self.config[\"d_model\"], kernel_size=1)\n",
    "    self.active = F.relu\n",
    "    self.dropout = nn.Dropout(self.config[\"dropout\"])\n",
    "\n",
    "  # inputs: (batch_size, n_seq, d_model)\n",
    "  def forward(self, inputs):\n",
    "    # (batch_size, n_seq, d_model) -> (batch_size, d_model, n_seq) -> (batch_size, d_ff, n_seq)\n",
    "    output = self.active(self.conv1(inputs.transpose(1,2)))\n",
    "    # (batch_size, d_ff, n_seq) -> (batch_size, d_model, n_seq) -> (batch_size, n_seq, d_model)\n",
    "    output = self.conv2(output).transpose(1,2)\n",
    "    output = self.dropout(output)\n",
    "    # output: (batch_size, n_seq, d_model)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "Af74qOF-tQOy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# attention pad mask\n",
    "def get_attn_pad_mask(query, key, i_pad):\n",
    "  '''\n",
    "  Args:\n",
    "      query: query(Q) (batch_size, 문장 내 토큰 개수)\n",
    "      key: key(K) (batch_size, 문장 내 토큰 개수)\n",
    "      * 전처리 했으므로 배치 내 토큰 개수 동일\n",
    "      i_pad: padding 인덱스 (=0)\n",
    "  '''\n",
    "  batch_size, len_q = query.size()\n",
    "  batch_size, len_k = key.size()\n",
    "  # (batch_size, len_q, len_k)\n",
    "  mask = key.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)\n",
    "  return mask\n",
    "\n",
    "\n",
    "# attention decoder mask\n",
    "def get_attn_decoder_mask(seq):\n",
    "  '''\n",
    "  Args:\n",
    "      seq: (batch_size, 문장 내 토큰 개수)\n",
    "  '''\n",
    "  mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n",
    "  # (batch_size, len_seq, len_seq)\n",
    "  mask = mask.triu(diagonal=1)\n",
    "  return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "_nfpAygWtRm2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.dropout = nn.Dropout(self.config[\"dropout\"])\n",
    "    self.scale = 1 / (self.config[\"d_h\"] ** 0.5)\n",
    "\n",
    "  def forward(self, Q, K, V, attn_mask):\n",
    "    '''\n",
    "    Args:\n",
    "        Q: (batch_size, h, len_q, d_h)\n",
    "        K: (batch_size, h, len_k, d_h)\n",
    "        V: (batch_size, h, len_v, d_h)\n",
    "        attn_mask: (batch_size, h, len_q, len_k)\n",
    "    '''\n",
    "    # (batch_size, h, len_q, len_k)\n",
    "    affinities = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
    "    affinities.masked_fill_(attn_mask, -1e9)\n",
    "    # (batch_size, h, len_q, len_k)\n",
    "    attn_weights = nn.Softmax(dim=-1)(affinities)\n",
    "    attn_weights = self.dropout(attn_weights)\n",
    "    # (batch_size, h, len_q, d_h)\n",
    "    output = torch.matmul(attn_weights, V)\n",
    "    # (batch_size, h, len_q, d_h), (batch_size, h, len_q, len_k)\n",
    "    return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "bczOeTv-tTFe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "    self.W_Q = nn.Linear(self.config['d_model'], self.config['h'] * self.config['d_h'])\n",
    "    self.W_K = nn.Linear(self.config['d_model'], self.config['h'] * self.config['d_h'])\n",
    "    self.W_V = nn.Linear(self.config['d_model'], self.config['h'] * self.config['d_h'])\n",
    "    self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n",
    "    self.linear = nn.Linear(self.config['h'] * self.config['d_h'], self.config['d_model'])\n",
    "    self.dropout = nn.Dropout(self.config['dropout'])\n",
    "\n",
    "  def forward(self, Q, K, V, attn_mask):\n",
    "    '''\n",
    "    Args:\n",
    "        Q: (batch_size, len_q, d_model)\n",
    "        K: (batch_size, len_q, d_model)\n",
    "        V: (batch_size, len_q, d_model)\n",
    "        attn_mask: (batch_size, len_q, len_k)\n",
    "    '''\n",
    "    # linearly project the queries, keys and values\n",
    "    # (batch_size, len_q, d_model) * (d_model, h * d_h) = (batch_size, len_q, h * d_h)\n",
    "    # -> (batch_size, len_q, h, d_h)\n",
    "    # -> (batch_size, h, len_q, d_h)\n",
    "    pjted_Q = self.W_Q(Q).view(self.config['batch_size'], -1, self.config['h'], self.config['d_h']).transpose(1,2)\n",
    "    pjted_K = self.W_K(K).view(self.config['batch_size'], -1, self.config['h'], self.config['d_h']).transpose(1,2)\n",
    "    pjted_V = self.W_V(V).view(self.config['batch_size'], -1, self.config['h'], self.config['d_h']).transpose(1,2)\n",
    "    # (batch_size, len_q, len_k) -> (batch_size, h, len_q, len_k)\n",
    "    attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config['h'], 1, 1)\n",
    "    # scaled dot product attention\n",
    "    # (batch_size, h, len_q, d_h), (batch_size, h, len_q, len_k)\n",
    "    context, attn_weights = self.scaled_dot_attn(pjted_Q, pjted_K, pjted_V, attn_mask)\n",
    "    # concat\n",
    "    # (batch_size, h, len_q, d_h) -> (batch_size, len_q, h * d_h)\n",
    "    context= context.transpose(1, 2).contiguous().view(self.config['batch_size'], -1, self.config['h'] * self.config['d_h'])\n",
    "    # linear\n",
    "    # (batch_size, len_q, h * d_h) * (h * d_h, d_model)\n",
    "    # -> (batch_size, len_q, d_model)\n",
    "    output = self.linear(context)\n",
    "    output = self.dropout(output)\n",
    "    # (batch_size, len_q, d_model), (batch_size, h, len_q, len_k)\n",
    "    return output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "X2h51mD5tVeS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder layer\n",
    "class EncoderLayer(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.self_attn = MultiHeadAttention(self.config)\n",
    "    self.layer_norm1 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "    self.ffn = FFN(self.config)\n",
    "    self.layer_norm2 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "\n",
    "  '''\n",
    "  Args:\n",
    "      inputs: (batch_size, len_seq, d_model)\n",
    "      attn_mask: (batch_size, len_q, len_k)\n",
    "  '''\n",
    "  def forward(self, inputs, attn_mask):\n",
    "    # (batch_size, len_q, d_model), (batch_size, h, len_q, len_k)\n",
    "    attn_output, attn_weights = self.self_attn(inputs, inputs, inputs, attn_mask)\n",
    "    # (batch_size, len_q, d_model)\n",
    "    attn_output = self.layer_norm1(inputs + attn_output)\n",
    "    # (batch_size, len_q, d_model)\n",
    "    ffn_output = self.ffn(attn_output)\n",
    "    # (batch_size, len_q, d_model)\n",
    "    ffn_output = self.layer_norm2(ffn_output + attn_output)\n",
    "    # (batch_size, len_q, d_model), (batch_size, h, len_q, len_k)\n",
    "    return ffn_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "yYRWsF2Dth-I",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# encoder\n",
    "class Encoder(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.enc_emb = nn.Embedding(self.config[\"n_enc_vocab\"], self.config[\"d_model\"])\n",
    "    pos_enc_table = torch.FloatTensor(get_sinusoidal(self.config[\"n_enc_seq\"] + 1, self.config[\"d_model\"]))\n",
    "    self.pos_emb = nn.Embedding.from_pretrained(pos_enc_table, freeze=True)\n",
    "\n",
    "    self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config[\"n_layer\"])])\n",
    "\n",
    "  '''\n",
    "  Args\n",
    "      inputs: (batch_size, len_seq)\n",
    "  '''\n",
    "  def forward(self, inputs):\n",
    "    # (batch_size, len_enc_seq)\n",
    "    positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
    "    pos_mask = inputs.eq(self.config[\"i_pad\"])\n",
    "    positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "    # (batch_size, len_enc_seq, d_model)\n",
    "    output = self.enc_emb(inputs) + self.pos_emb(positions)\n",
    "\n",
    "    # (batch_size, len_enc_seq, len_enc_seq)\n",
    "    attn_mask = get_attn_pad_mask(inputs, inputs, self.config[\"i_pad\"])\n",
    "\n",
    "    attn_weights_history = list([])\n",
    "    for layer in self.layers:\n",
    "      # (batch_size, len_enc_seq, d_model), (batch_size, h, len_enc_seq, len_enc_seq)\n",
    "      output, attn_weights = layer(output, attn_mask)\n",
    "      attn_weights_history.append(attn_weights)\n",
    "\n",
    "    # (batch_size, len_enc_seq, d_model), [(batch_size, h, len_enc_seq, len_enc_seq)]\n",
    "    return output, attn_weights_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "kuG4-Jn80FkD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.self_attn = MultiHeadAttention(self.config)\n",
    "    self.layer_norm1 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "    self.dec_enc_attn = MultiHeadAttention(self.config)\n",
    "    self.layer_norm2 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "    self.ffn = FFN(self.config)\n",
    "    self.layer_norm3 = nn.LayerNorm(self.config[\"d_model\"], eps = self.config[\"layer_norm_epsilon\"])\n",
    "\n",
    "  '''\n",
    "  Args:\n",
    "      dec_inputs: (batch_size, len_seq, d_model)\n",
    "      enc_outputs: (batch_size, len_enc_seq, d_model)\n",
    "      self_attn_mask: (batch_size, len_dec_seq, len_dec_seq)\n",
    "      dec_enc_attn_mask: (batch_size, len_dec_seq, len_enc_seq)\n",
    "  '''\n",
    "  def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq)\n",
    "    self_attn_output, self_attn_weights = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n",
    "    self_attn_output = self.layer_norm1(dec_inputs + self_attn_output)\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "    dec_enc_attn_output, dec_enc_attn_weights = self.dec_enc_attn(self_attn_output, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "    dec_enc_attn_output = self.layer_norm2(self_attn_output + dec_enc_attn_output)\n",
    "    # (batch_size, len_dec_seq, d_model)\n",
    "    ffn_output = self.ffn(dec_enc_attn_output)\n",
    "    ffn_output = self.layer_norm3(dec_enc_attn_output + ffn_output)\n",
    "    # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "    return ffn_output, self_attn_weights, dec_enc_attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1701147084879,
     "user": {
      "displayName": "김다인",
      "userId": "01778217432812470937"
     },
     "user_tz": -540
    },
    "id": "uDhoza9D8w4T",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  def __init__(self, config):\n",
    "    super().__init__()\n",
    "    self.config = config\n",
    "\n",
    "    self.dec_emb = nn.Embedding(self.config[\"n_dec_vocab\"], self.config[\"d_model\"])\n",
    "    pos_enc_table = torch.FloatTensor(get_sinusoidal(self.config[\"n_dec_seq\"] + 1, self.config[\"d_model\"]))\n",
    "    self.pos_emb = nn.Embedding.from_pretrained(pos_enc_table, freeze=True)\n",
    "\n",
    "    self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config[\"n_layer\"])])\n",
    "\n",
    "  '''\n",
    "  Args:\n",
    "      dec_inputs: (batch_size, len_dec_seq, d_model)\n",
    "      enc_inputs: (batch_size, len_enc_seq, d_model)\n",
    "      enc_outputs: (batch_size, len_enc_seq, d_model)\n",
    "  '''\n",
    "  def forward(self, dec_inputs, enc_inputs, enc_outputs):\n",
    "    # (batch_size, len_enc_seq)\n",
    "    positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n",
    "    pos_mask = dec_inputs.eq(self.config[\"i_pad\"])\n",
    "    positions.masked_fill_(pos_mask, 0)\n",
    "\n",
    "    # (batch_size, n_dec_seq, d_model)\n",
    "    dec_output = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n",
    "\n",
    "    # (batch_size, len_dec_seq, len_dec_seq)\n",
    "    attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config[\"i_pad\"])\n",
    "    # (batch_size, len_dec_seq, len_dec_seq)\n",
    "    attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n",
    "    # (batch_size, len_dec_seq, len_dec_seq)\n",
    "    self_attn_mask = torch.gt((attn_pad_mask + attn_decoder_mask), 0)\n",
    "    # (batch_size, len_dec_seq, len_enc_seq)\n",
    "    dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config[\"i_pad\"])\n",
    "\n",
    "    self_attn_weights_history, dec_enc_attn_weights_history = list([]), list([])\n",
    "    for layer in self.layers:\n",
    "      # (batch_size, len_dec_seq, d_model), (batch_size, h, len_dec_seq, len_dec_seq), (batch_size, h, len_dec_seq, len_ebc_seq)\n",
    "      output, self_attn_weights, dec_enc_attn_weights = layer(dec_output, enc_outputs, self_attn_mask, dec_enc_attn_mask)\n",
    "      self_attn_weights_history.append(self_attn_weights)\n",
    "      dec_enc_attn_weights_history.append(dec_enc_attn_weights)\n",
    "    # (batch_size, len_dec_seq, d_model), [(batch_size, h, len_dec_seq, len_dec_seq)], [(batch_size, h, len_dec_seq, len_ebc_seq)]\n",
    "    return output, self_attn_weights_history, dec_enc_attn_weights_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        self.encoder = Encoder(self.config)\n",
    "        self.decoder = Decoder(self.config)\n",
    "    \n",
    "    def forward(self, enc_inputs, dec_inputs):\n",
    "        # (batch_size, len_enc_seq, d_model), [(batch_size, h, len_enc_seq, len_enc_seq)]\n",
    "        enc_outputs, enc_self_attn_weights_history = self.encoder(enc_inputs)\n",
    "        # (batch_size, len_dec_seq, d_model), [(batch_size, h, len_dec_seq, len_dec_seq)], [(batch_size, h, len_dec_seq, len_ebc_seq)]\n",
    "        dec_outputs, dec_self_attn_weights_history, dec_enc_attn_weights_history = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n",
    "        # (batch_size, len_dec_seq, d_model), [(batch_size, h, len_enc_seq, len_enc_seq)],\n",
    "        # [(batch_size, h, len_dec_seq, len_dec_seq)], [(batch_size, h, len_dec_seq, len_ebc_seq)]\n",
    "        return dec_outputs, enc_self_attn_weights_history, dec_self_attn_weights_history, dec_enc_attn_weights_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def returnExampleBatch():\n",
    "  cnt = 0\n",
    "  for [enc, dec] in loader:\n",
    "   if (cnt < 1):\n",
    "      return enc, dec\n",
    "   else:\n",
    "      break\n",
    "\n",
    "q, k = returnExampleBatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp_config[\"n_enc_seq\"] = q.size(1)\n",
    "tmp_config[\"n_dec_seq\"] = k.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(tmp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dec_outputs, enc_self_attn_weights_history, dec_self_attn_weights_history, dec_enc_attn_weights_history = transformer(q, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6684, -0.1634, -0.4582,  ...,  0.0436, -0.3301,  0.2300],\n",
       "         [-0.3527, -0.8143,  0.5640,  ..., -1.5524, -2.7957,  1.1874],\n",
       "         [ 0.4643, -1.4126, -1.0146,  ...,  2.4775, -0.8689,  1.4743],\n",
       "         ...,\n",
       "         [ 1.1099,  0.8237, -1.3496,  ..., -0.4410, -0.5183,  1.2187],\n",
       "         [ 1.1340,  0.8649, -1.3344,  ..., -0.7411, -0.5506,  1.1182],\n",
       "         [ 1.1284,  0.8886, -1.3049,  ..., -0.3644, -0.5333,  1.1483]],\n",
       "\n",
       "        [[-0.6268, -0.5419, -0.8031,  ...,  0.1300, -0.1310,  0.5507],\n",
       "         [-0.5160, -0.5924, -2.3623,  ...,  0.4685, -1.3419,  1.6644],\n",
       "         [-1.1154, -0.5856, -0.5961,  ...,  2.3031,  1.1585,  1.1080],\n",
       "         ...,\n",
       "         [ 1.1860,  0.5093, -1.0463,  ..., -0.0348, -0.4950,  1.4005],\n",
       "         [ 1.1327,  0.5200, -1.2506,  ..., -0.0713, -0.5912,  1.1135],\n",
       "         [ 1.1049,  0.6109, -0.8801,  ..., -0.4539, -0.6391,  1.1499]],\n",
       "\n",
       "        [[ 0.3794,  0.9222, -1.7307,  ..., -0.7747, -0.1287,  0.4227],\n",
       "         [-0.4887, -0.1143, -2.4089,  ...,  0.1660, -1.4162,  1.8485],\n",
       "         [ 0.3687, -1.4486, -0.0146,  ..., -0.7343,  0.6239,  0.2618],\n",
       "         ...,\n",
       "         [ 1.2781,  0.9543, -1.4612,  ..., -0.4784, -0.5554,  1.2416],\n",
       "         [ 1.0453,  1.0432, -1.5924,  ..., -0.2224, -0.5587,  1.2098],\n",
       "         [ 1.0264,  0.9489, -1.5411,  ..., -0.2816, -0.3866,  1.1877]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.2582, -0.1285, -1.4977,  ..., -0.2796, -0.3277,  0.3634],\n",
       "         [-0.2787, -0.1215, -0.6051,  ..., -0.1866, -0.7736,  0.9349],\n",
       "         [-1.2423, -2.8891, -0.6313,  ...,  0.6115, -0.6309, -1.8316],\n",
       "         ...,\n",
       "         [ 1.3496,  0.6731, -1.3317,  ..., -0.4437, -0.4333,  1.1890],\n",
       "         [ 1.2567,  0.6966, -1.2581,  ..., -0.2485, -0.3568,  1.2156],\n",
       "         [ 1.2400,  0.7406, -1.2717,  ..., -0.3692, -0.5514,  1.2341]],\n",
       "\n",
       "        [[ 0.7809, -1.3207,  0.6012,  ..., -0.2568,  0.7547,  1.0659],\n",
       "         [ 0.1517, -0.3358, -1.1264,  ...,  1.8350, -0.4796,  1.4547],\n",
       "         [-0.3503, -1.8783, -0.3759,  ...,  1.2610, -0.4135,  0.4329],\n",
       "         ...,\n",
       "         [ 1.0815,  0.6051, -0.8921,  ..., -0.5445, -0.3829,  1.2476],\n",
       "         [ 1.0979,  0.6439, -1.2440,  ..., -0.3684, -0.4181,  1.3486],\n",
       "         [ 1.1040,  0.6128, -0.7965,  ..., -0.3515, -0.3169,  1.3490]],\n",
       "\n",
       "        [[ 2.0381, -0.0302, -0.1455,  ...,  0.6430, -0.4743,  0.6472],\n",
       "         [ 1.4777,  0.7956, -0.1349,  ...,  2.0114, -0.8742,  0.3111],\n",
       "         [-0.9671, -1.1613, -1.2372,  ...,  0.4088, -0.2725,  0.6157],\n",
       "         ...,\n",
       "         [ 1.4075,  0.5253, -1.2020,  ..., -0.2551, -0.5226,  1.0183],\n",
       "         [ 1.1726,  0.5447, -1.2254,  ..., -0.3525, -0.5596,  1.3994],\n",
       "         [ 1.0708,  0.6080, -1.2389,  ..., -0.2770, -0.7432,  1.1152]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 136, 512])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8, 111, 111])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc_self_attn_weights_history[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8, 136, 136])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_self_attn_weights_history[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 8, 136, 111])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_enc_attn_weights_history[0].size()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyPsoty5ZvCk1uE7m9MmeNpy",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "dnkim419",
   "language": "python",
   "name": "dnkim419"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
